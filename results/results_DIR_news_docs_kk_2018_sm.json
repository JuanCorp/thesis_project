{"teacher_coherence": 0.017400081653875837, "teacher_top_tokens": [["beogradu", "rekao", "strane", "predsednika", "protiv", "pred", "kojima", "mediji", "drugi", "predsednik"], ["srbije", "ka\u017ee", "srbiji", "bbc", "jer", "oni", "srpskom", "nema", "navodi", "ili"], ["izme\u0111u", "predsednik", "sad", "zemlje", "vi\u0161e", "odsto", "biti", "images", "getty", "prema"], ["predsednik", "sad", "rekao", "zbog", "nakon", "zemlje", "srbije", "afp", "ponovo", "jo\u0161"], ["rekao", "predsednik", "sad", "predsednika", "dr\u017eave", "afp", "izjavio", "nakon", "tako\u0111e", "vlade"], ["srbije", "predsednik", "ka\u017ee", "godina", "smatra", "bbc", "pitanje", "zbog", "images", "sad"], ["tri", "skoro", "te\u0161ko", "nego", "gotovo", "toga", "poput", "posle", "ima", "mogao"], ["predsednik", "rekao", "sad", "izme\u0111u", "zemlje", "izjavio", "predsednika", "vlada", "dr\u017eave", "reuters"], ["beogradu", "policija", "vlade", "jednog", "pre", "dodaje", "godinu", "po\u0161to", "protiv", "strane"], ["srbiji", "iako", "po\u0161to", "strane", "bbc", "\u017eivot", "neke", "drugi", "jednog", "problem"], ["srbije", "nema", "srbiji", "ka\u017ee", "bio", "bbc", "srpskom", "jer", "dok", "dana"], ["bio", "sam", "smo", "jo\u0161", "ka\u017ee", "nakon", "mo\u017ee", "bilo", "tada", "srbije"], ["tri", "nego", "gotovo", "gde", "poput", "broj", "posle", "ovoj", "toga", "te\u0161ko"], ["srbije", "ka\u017ee", "bbc", "smo", "jer", "srbiji", "bio", "sam", "jo\u0161", "sve"], ["ka\u017ee", "bio", "srbiji", "ili", "sam", "ljudi", "samo", "prema", "bbc", "sve"], ["tome", "sam", "\u010dak", "ljudi", "smo", "ne\u0161to", "kad", "ili", "mogu", "bila"], ["odsto", "izme\u0111u", "getty", "images", "biti", "vi\u0161e", "oko", "poput", "zemlje", "tako\u0111e"], ["sam", "bio", "bila", "bilo", "ka\u017ee", "sve", "kad", "ona", "dok", "ljudi"], ["ljudi", "ili", "vi\u0161e", "mogu", "odsto", "koliko", "manje", "kod", "tome", "treba"], ["sam", "bio", "bila", "kad", "smo", "bilo", "prvi", "tako", "sve", "put"]], "teacher_diversity": 0.46, "dataset": "ted_talks", "embedding_method": "Pre-trained embeddings", "model": "GMM", "topic_method": "tf", "language": "urdu", "dataset_length": 1315, "average_document_length": 53.0, "vocab_size": 238, "embedding_model": "BERT", "training_time": 18.69455099105835}