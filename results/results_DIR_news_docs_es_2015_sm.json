{"teacher_coherence": 0.007063137573620468, "teacher_top_tokens": [["son", "sus", "pero", "todo", "tambi\u00e9n", "sobre", "esta", "ser", "puede", "d\u00eda"], ["centro", "euros", "medio", "mes", "jos\u00e9", "social", "trav\u00e9s", "total", "nueva", "ciudad"], ["sus", "pero", "han", "esta", "son", "todo", "hay", "cuando", "ser", "tambi\u00e9n"], ["son", "ser", "sus", "hay", "les", "puede", "nos", "pero", "todo", "sobre"], ["pero", "sus", "000", "est\u00e1", "hay", "son", "puede", "han", "esta", "todo"], ["han", "pero", "000", "sus", "esta", "informado", "tambi\u00e9n", "son", "seg\u00fan", "d\u00eda"], ["dos", "fue", "fueron", "tras", "seg\u00fan", "lugar", "hab\u00eda", "horas", "sido", "informado"], ["millones", "a\u00f1o", "mes", "euros", "total", "respecto", "seg\u00fan", "2014", "han", "hasta"], ["sus", "son", "pero", "tambi\u00e9n", "todos", "puede", "hace", "hay", "forma", "desde"], ["equipo", "ante", "partido", "fue", "final", "madrid", "pero", "primer", "dos", "tras"], ["son", "sus", "pero", "tambi\u00e9n", "puede", "cuando", "han", "as\u00ed", "est\u00e1", "personas"], ["gobierno", "presidente", "partido", "pol\u00edtica", "sobre", "acuerdo", "estado", "general", "contra", "porque"], ["sus", "pero", "est\u00e1", "han", "son", "desde", "hay", "ser", "a\u00f1os", "todos"], ["tambi\u00e9n", "pero", "sus", "ser", "entre", "sin", "hay", "puede", "esta", "han"], ["pero", "son", "puede", "hay", "eso", "sus", "pueden", "est\u00e1n", "sin", "ser"], ["pero", "sus", "hay", "han", "esta", "son", "000", "tambi\u00e9n", "sin", "est\u00e1"], ["sus", "tambi\u00e9n", "han", "pero", "ser", "son", "esta", "000", "hay", "sin"], ["pero", "era", "muy", "sus", "cuando", "nos", "todo", "porque", "a\u00f1os", "sin"], ["pero", "000", "esta", "tambi\u00e9n", "ser", "sus", "han", "informado", "hay", "puede"], ["millones", "euros", "gobierno", "seg\u00fan", "esta", "000", "informado", "han", "total", "a\u00f1o"]], "teacher_diversity": 0.35, "dataset": "ted_talks", "embedding_method": "Pre-trained embeddings", "model": "GMM", "topic_method": "tf", "language": "urdu", "dataset_length": 445334, "average_document_length": 36.0, "vocab_size": 182, "embedding_model": "BERT", "training_time": 2910.4194757938385}